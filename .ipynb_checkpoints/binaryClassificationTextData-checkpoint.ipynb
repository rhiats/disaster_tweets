{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict whether or not a tweet is about a real disaster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview\n",
    "\n",
    "There are 7,613 training data points and 3,263 test datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_shape(filename):\n",
    "    \"\"\"\n",
    "        Return the shape (row,columns) of the dataset in the .csv file\n",
    "        \n",
    "        @P: filename (string) of a csv data set file\n",
    "        @R: tuple of dataframe size\n",
    "        \n",
    "    \"\"\"\n",
    "    df=pd.read_csv(filename)\n",
    "    return df.shape\n",
    "\n",
    "def hist_rel_freq(filename,columnName,mx_val):\n",
    "    \"\"\"\n",
    "        Save a relative frequency of a specific column\n",
    "        \n",
    "        @P: filename: (csv) the training data file\n",
    "            columnName: (dtring) the name of the column of interest\n",
    "            mx_val: (int) the max range for the x-axis\n",
    "            \n",
    "    \"\"\"\n",
    "    df=pd.read_csv(filename)\n",
    "    fig, ax = plt.subplots()\n",
    "    g=sns.histplot(data=df, x=columnName, stat=\"percent\", discrete=True, ax=ax)\n",
    "    ax.set_xlim(-1,mx_val+1)\n",
    "    ax.set_xticks(range(0,mx_val+1))\n",
    "    plt.savefig('output/dist_{}.png'.format(columnName))\n",
    "    print(\"\\n Column: {} Relative Frequency \\n\".format(columnName),df[columnName].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training data is (7613, 5) \n",
      "The shape of the test data is (3263, 4) \n",
      "\n",
      " Column: target Relative Frequency \n",
      " 0    0.57034\n",
      "1    0.42966\n",
      "Name: target, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAON0lEQVR4nO3df6zddX3H8eeLAgIDBcZdg7RYBg0L+0GNd8iPZQk4F9xwdNGhzrn+0a0af2FcdGxx2ZaYRRejWxY3bYTRP1SKTFPsMjfSoWQiyC2ggEhABtIK9KL81CgU3vvjfO+4lNvew6Xfc3r7eT6Sm3O+33O+Pe+m6bPffs8532+qCklSOw4Y9wCSpNEy/JLUGMMvSY0x/JLUGMMvSY05cNwDDOOYY46pFStWjHsMSVpUtm7d+lBVTey6flGEf8WKFUxNTY17DElaVJLcO9d6D/VIUmMMvyQ1xvBLUmMMvyQ1xvBLUmMMvyQ1xvBLUmMMvyQ1xvBLUmMWxTd393fHLT+eH2y7b9xjaAFevmw52+/7/rjHkF4Qw78P+MG2+3jTp68d9xhagI1vP3PcI0gvmId6JKkxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGtPrxdaT3AM8DjwN7KyqySRHAxuBFcA9wAVV9XCfc0iSnjWKPf6zq2pVVU12yxcBW6pqJbClW5Ykjcg4DvWcD2zo7m8AVo9hBklqVt/hL+C/kmxNsq5bt7Sq7u/uPwAsnWvDJOuSTCWZmp6e7nlMSWpHr8f4gd+oqu1JfgG4Ksl3Zz9YVZWk5tqwqtYD6wEmJyfnfI4k6YXrdY+/qrZ3tzuALwGnAQ8mORagu93R5wySpOfqLfxJfi7JETP3gd8GbgWuBNZ0T1sDbOprBknS8/V5qGcp8KUkM6/zuar6SpIbgMuTrAXuBS7ocQZJ0i56C39V3Q2cOsf6HwKv6et1JUl75jd3Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGtPbxdalJhxwIEnGPYUW6OXLlrP9vu+Pe4yRM/zSi/HMTt706WvHPYUWaOPbzxz3CGPhoR5Jaozhl6TGGH5Jaozhl6TGGH5Jakzv4U+yJMlNSTZ3yyckuT7JXUk2Jjm47xkkSc8axR7/hcDts5Y/Cnyiqk4CHgbWjmAGSVKn1/AnWQb8LvCZbjnAOcAV3VM2AKv7nEGS9Fx97/H/A/BB4Jlu+eeBR6pqZ7e8DTiu5xkkSbP0Fv4k5wE7qmrrArdfl2QqydT09PRenk6S2tXnHv9ZwO8luQe4jMEhnn8Ejkwyc6qIZcD2uTauqvVVNVlVkxMTEz2OKUlt6S38VfUXVbWsqlYAbwb+u6reClwNvLF72hpgU18zSJKebxyf4/9z4P1J7mJwzP/iMcwgSc0aydk5q+qrwFe7+3cDp43idSVJz+c3dyWpMYZfkhpj+CWpMYZfkhpj+CWpMYZfkhpj+CWpMYZfkhpj+CWpMYZfkhpj+CWpMYZfkhpj+CWpMYZfkhpj+CWpMUOFP8lZw6yTJO37ht3j/6ch10mS9nF7vAJXkjOAM4GJJO+f9dBLgSV9DiZJ6sd8l148GDi8e94Rs9Y/xrMXTJckLSJ7DH9VfQ34WpJLq+reEc0kSerRsBdbf0mS9cCK2dtU1Tl9DCVJ6s+w4f8C8CngM8DT/Y0jSerbsOHfWVX/0uskkqSRGPbjnF9O8s4kxyY5euan18kkSb0Ydo9/TXf7gVnrCvjFvTuOJKlvQ4W/qk7oexBJ0mgMe8qGw5J8qPtkD0lWJjmv39EkSX0Y9hj/vwJPMvgWL8B24MO9TCRJ6tWw4T+xqv4eeAqgqn4CZE8bJDkkyTeTfCvJbUn+tlt/QpLrk9yVZGOSg1/U70CS9IIMG/4nkxzK4A1dkpwI/GyebX4GnFNVpwKrgHOTnA58FPhEVZ0EPAysXcjgkqSFGTb8fw18BVie5LPAFuCDe9qgBp7oFg/qfgo4B7iiW78BWP0CZ5YkvQjDfqrnqiQ3AqczOMRzYVU9NN92SZYAW4GTgE8C3wMeqaqd3VO2AcftZtt1wDqA448/fpgxJUlDGPZTPb/P4Nu7/15Vm4GdSVbPt11VPV1Vq4BlwGnALw07WFWtr6rJqpqcmJgYdjNJ0jyGPtRTVY/OLFTVIwwO/wyle/7VwBnAkUlm/qexjMEnhCRJIzJs+Od63nwXcZlIcmR3/1DgtcDtDP4BmDmX/xpg05AzSJL2gmFP2TCV5OMMjtMDvIvBsfs9ORbY0B3nPwC4vKo2J/kOcFmSDwM3ARcvYG5J0gING/73AH8FbGTwyZyrGMR/t6rq28Ar51h/N4Pj/ZKkMZg3/N0e++aqOnsE80iSejbvMf6qehp4JsnLRjCPJKlnwx7qeQK4JclVwI9nVlbVe3uZSpLUm2HD/8XuR5K0yA37zd0N3Ucyj6+qO3qeSZLUo2G/uft64GYG5+shyaokV/Y4lySpJ8N+getvGHwE8xGAqroZL7soSYvSsOF/avYpGzrP7O1hJEn9G/bN3duS/CGwJMlK4L3Atf2NJUnqy7B7/O8BfpnBxVU+BzwKvK+nmSRJPZrvRGuHAO9gcD79W4AzZp1LX5K0CM23x78BmGQQ/dcBH+t9IklSr+Y7xn9KVf0qQJKLgW/2P5IkqU/z7fE/NXPHQzyStH+Yb4//1CSPdfcDHNoth8H11F/a63SSpL1uj+GvqiWjGkSSNBrDfpxTkrSfMPyS1BjDL0mNMfyS1BjDL0mNMfyS1BjDL0mNMfyS1BjDL0mNMfyS1BjDL0mN6S38SZYnuTrJd5LcluTCbv3RSa5Kcmd3e1RfM0iSnq/PPf6dwJ9V1SnA6cC7kpwCXARsqaqVwJZuWZI0Ir2Fv6rur6obu/uPA7cDxwHnM7iyF93t6r5mkCQ930iO8SdZAbwSuB5YWlX3dw89ACzdzTbrkkwlmZqenh7FmJLUhN7Dn+Rw4N+A91XVY7Mfq6oCaq7tqmp9VU1W1eTExETfY0pSM3oNf5KDGET/s1X1xW71g0mO7R4/FtjR5wySpOfq81M9AS4Gbq+qj8966EpgTXd/DbCprxkkSc833zV3X4yzgLcBtyS5uVv3l8BHgMuTrAXuBS7ocQZJ0i56C39V/Q+Di7LP5TV9va4kac/85q4kNcbwS1JjDL8kNcbwS1JjDL8kNcbwS1JjDL8kNcbwS1JjDL8kNcbwS1JjDL8kNcbwS1JjDL8kNcbwS1JjDL8kNcbwS1JjDL8kNcbwS1JjDL8kNcbwS1JjDL8kNcbwS1JjDL8kNcbwS1JjDL8kNcbwS1JjDL8kNaa38Ce5JMmOJLfOWnd0kquS3NndHtXX60uS5tbnHv+lwLm7rLsI2FJVK4Et3bIkaYR6C39VXQP8aJfV5wMbuvsbgNV9vb4kaW6jPsa/tKru7+4/ACzd3ROTrEsylWRqenp6NNNJUgPG9uZuVRVQe3h8fVVNVtXkxMTECCeTpP3bqMP/YJJjAbrbHSN+fUlq3qjDfyWwpru/Btg04teXpOb1+XHOzwPfAE5Osi3JWuAjwGuT3An8VrcsSRqhA/v6havqLbt56DV9vaYkaX5+c1eSGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4Jakxhl+SGmP4JakxYwl/knOT3JHkriQXjWMGSWrVyMOfZAnwSeB1wCnAW5KcMuo5JKlV49jjPw24q6rurqongcuA88cwhyQ1KVU12hdM3gicW1V/0i2/DXh1Vb17l+etA9Z1iycDd4x0UO0txwAPjXsILZh/fovbK6pqYteVB45jkmFU1Xpg/bjn0IuTZKqqJsc9hxbGP7/90zgO9WwHls9aXtatkySNwDjCfwOwMskJSQ4G3gxcOYY5JKlJIz/UU1U7k7wb+E9gCXBJVd026jk0Mh6uW9z889sPjfzNXUnSePnNXUlqjOGXpMYYfvXGU3MsXkkuSbIjya3jnkV7n+FXLzw1x6J3KXDuuIdQPwy/+uKpORaxqroG+NG451A/DL/6chxw36zlbd06SWNm+CWpMYZfffHUHNI+yvCrL56aQ9pHGX71oqp2AjOn5rgduNxTcyweST4PfAM4Ocm2JGvHPZP2Hk/ZIEmNcY9fkhpj+CWpMYZfkhpj+CWpMYZfkhpj+NW8JEcmeecIXme1J6rTvsDwS3AkMHT4M7CQvzurGZypVBorP8ev5iWZOXPoHcDVwK8BRwEHAR+qqk1JVjD4Mtr1wKuA3wH+GPgjYJrBCem2VtXHkpzI4JTUE8BPgD8FjgY2A492P2+oqu+N6vcozTbyi61L+6CLgF+pqlVJDgQOq6rHkhwDXJdk5lQTK4E1VXVdkl8H3gCcyuAfiBuBrd3z1gPvqKo7k7wa+OeqOqf7dTZX1RWj/M1JuzL80nMF+Lskvwk8w+BU0ku7x+6tquu6+2cBm6rqp8BPk3wZIMnhwJnAF5LM/JovGdXw0jAMv/Rcb2VwiOZVVfVUknuAQ7rHfjzE9gcAj1TVqn7Gk14839yV4HHgiO7+y4AdXfTPBl6xm22+Drw+ySHdXv55AFX1GPC/Sf4A/v+N4FPneB1pbAy/mldVPwS+3l1YfBUwmeQWBm/efnc329zA4DTT3wb+A7iFwZu2MPhfw9ok3wJu49lLTl4GfCDJTd0bwNJY+KkeaYGSHF5VTyQ5DLgGWFdVN457Lmk+HuOXFm5994WsQ4ANRl+LhXv8ktQYj/FLUmMMvyQ1xvBLUmMMvyQ1xvBLUmP+Dzd2NzE1ZWkfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"The shape of the training data is {} \".format(df_shape(\"input/train.csv\")))\n",
    "print(\"The shape of the test data is {} \".format(df_shape(\"input/test.csv\")))\n",
    "hist_rel_freq(\"input/train.csv\",\"target\",1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"input/train.csv\")\n",
    "\n",
    "X=df.drop('target', axis=1, inplace=False)\n",
    "y=df['target']\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(df, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process\n",
    "\n",
    "• Convert all the words to lowercase\n",
    "\n",
    "• Lemmatize all thewords (i.e., convert every word to its root so that all of “running,” “run,” and “runs” are converted to “run” and and all of “good,” “well,” “better,” and “best” are converted to “good”; this is easily done using nltk.stem) - (CHOSE NOT TO LEMMATIZE, TO PRESERVE MEANING OF TEXT - CONSIDER WRITING MY OWN FUNCTION)\n",
    "\n",
    "• Strip punctuation\n",
    "\n",
    "• Strip the stop words, e.g., “the”, “and”, “or” (ADDITIONAL STOP WORDS?)\n",
    "\n",
    "• Strip @ and urls (It’s Twitter.)\n",
    "\n",
    "• Something else? Tell us about it (SPELL CHECK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lower(col_name,dataF):\n",
    "    \"\"\"\n",
    "        Convert all words to lowercase.\n",
    "        \n",
    "        @P: \n",
    "        col (string): Name of column in a dataframe that contains text data\n",
    "        dataF (dataframe): Dataframe with the text data that needs modifying\n",
    "        \n",
    "    \"\"\"\n",
    "    dataF[col_name]=dataF[col_name].str.lower()\n",
    "    \n",
    "def remove_punctuation(col_name,dataF):\n",
    "    \"\"\"\n",
    "        Remove the punctuation in a column with text data.\n",
    "        \n",
    "        @P: \n",
    "        col (string): Name of column in a dataframe that contains text data\n",
    "        dataF (dataframe): Dataframe with the text data that needs modifying\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    #Regex to identify anything that is not a word or string\n",
    "    dataF[col_name]=dataF[col_name].str.replace(r'[^\\w\\s]+','') \n",
    "\n",
    "def remove_tag(txt_col):\n",
    "    \"\"\"\n",
    "        Remove the @'username' in a column with text data.\n",
    "        \n",
    "        @P: \n",
    "        txt_col (series): Dataframe column that contains text data.\n",
    "        \n",
    "        @R:\n",
    "        s (string): String without @'username'.\n",
    "        \n",
    "    \"\"\"\n",
    "    words = word_tokenize(txt_col)\n",
    "    \n",
    "    j=-1\n",
    "    w_arr=[]\n",
    "    for i in range(len(words)):\n",
    "        if words[i]=='@': j=i+1\n",
    "        \n",
    "        if words[i]!='@' and i!=j: w_arr.append(words[i])\n",
    "    \n",
    "    s=\" \".join(w_arr)\n",
    "    return s\n",
    "\n",
    "def remove_url(txt_col):\n",
    "    \"\"\"\n",
    "        Remove the url in a column with text data.\n",
    "        \n",
    "        @P: \n",
    "        txt_col (series): Dataframe column that contains text data.\n",
    "        \n",
    "        @R:\n",
    "        s (string): String without url.\n",
    "        \n",
    "    \"\"\"\n",
    "    words = word_tokenize(txt_col)\n",
    "    w_arr=[ w for w in words if not w.startswith('http')]\n",
    "    s=\" \".join(w_arr)\n",
    "    return s\n",
    "\n",
    "def lematize_txt(txt_col):\n",
    "    \"\"\"\n",
    "        Stem words.\n",
    "        \n",
    "        @P: \n",
    "        txt_col (series): Dataframe column that contains text data.\n",
    "        \n",
    "        @R:\n",
    "        s (string): String of lematized text\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    ps = PorterStemmer()\n",
    "    words = word_tokenize(txt_col)\n",
    "    w_arr=[ps.stem(w) for w in words]\n",
    "    s=\" \".join(w_arr)\n",
    "    return s\n",
    "\n",
    "def rmv_stop_wrds(txt_col):\n",
    "    \"\"\"\n",
    "        Remove stop words.\n",
    "        \n",
    "        @P: \n",
    "        txt_col (series): Dataframe column that contains text data.\n",
    "        \n",
    "        @R:\n",
    "        s (string): String of text without stop words.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(txt_col)\n",
    "    w_arr=[w for w in words if not w.lower() in stop_words]\n",
    "    s=\" \".join(w_arr)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_lower(\"text\",df)\n",
    "df['text'] = df.apply(lambda x: remove_tag(x['text']),axis=1)\n",
    "remove_punctuation(\"text\",df)\n",
    "df['text'] = df.apply(lambda x: rmv_stop_wrds(x['text']),axis=1)\n",
    "df['text'] = df.apply(lambda x: remove_url(x['text']),axis=1)\n",
    "\n",
    "df.to_csv(\"output/ck_pre_proc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
